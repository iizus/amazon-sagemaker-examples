{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 背景\n",
    "- Bedrockのbatch推論のquotaがon demandと関係ない（だからquotaに引っ掛からなくてうれしい）と言う説\n",
    "- text to image (SDXL or Titan or Both)で500枚くらいバッチ推論ジョブを発行してどんな風に実行が完了するか（もしくは完了しないか）を見てみる\n",
    "- On demandのquotaより明らかに早かったら嬉しい\n",
    "\n",
    "\n",
    "## 検証条件\n",
    "- 推論方式: バッチ\n",
    "- 生成: テキスト → 画像\n",
    "- モデル:\n",
    "    - amazon.titan-image-generator-v1\n",
    "    - stability.stable-diffusion-xl-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "### 入出力データ\n",
    "- インターフェイスはS3のみ。\n",
    "- バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- 最小も最大も定義されている。\n",
    "\n",
    "#### 入力データフォーマット\n",
    "- 一枚一枚に対してはオンデマンド推論と同じ。それをJSONLにしてS3に置く。\n",
    "- リクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "    - Titan: 4枚\n",
    "    - SD: 10枚\n",
    "\n",
    "#### 出力データフォーマット\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにバイナリで全画像が入力情報とセットで埋まっている。大量画像入っているのでデカJSONL\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない\n",
    "\n",
    "### ジョブ\n",
    "- ジョブは並列実行されない。\n",
    "- 複数のジョブを投げることは可能だが、順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "- よってジョブの並列実行による高速化はされない。\n",
    "- またバッチ推論にすることでオンラインより高速化もされない。\n",
    "- バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。\n",
    "\n",
    "### 結果\n",
    "600枚全て成功\n",
    "\n",
    "- Titan: 12 sec / image\n",
    "- SD: 7 sec /image　← 70分くらい\n",
    "\n",
    "条件全て揃えられているわけではないので注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公開情報\n",
    "- 開発者ドキュメント: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html\n",
    "- Quota: https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- コードサンプル: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-example.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境準備\n",
    "\n",
    "### 2024.2.1\n",
    "- Public Preview\n",
    "- 利用方法\n",
    "    - REST API: あると思うが面倒\n",
    "    - CLI: 無さそう\n",
    "    - SDK: プレビューのがある\n",
    "        - PythonとJavaのみ\n",
    "        - ただし他サービスと同様、プレビュー状態のAPIは一般公開SDKに含まれていない\n",
    "        - そのため以下の公式whlからインストールが必要\n",
    "        - https://d2eo22ngex1n9g.cloudfront.net/Documentation/SDK/bedrock-python-sdk-reinvent.zip\n",
    "    - コンソール: 無さそう\n",
    "\n",
    "Python SDKを使うこととし、以下でSDKのインストールをする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! chmod +x install_sdk.sh\n",
    "! ./install_sdk.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記実行後、カーネルの再起動が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import Application\n",
    "Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```aws s3 cp``` などをするため、AWS CLIがあるか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! aws --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データフォーマット\n",
    "\n",
    "参考: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html\n",
    "\n",
    "以下、サンプルの入力JSON\n",
    "\n",
    "入力JSON Linesフォーマット\n",
    "```JSON\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {JSON body}\n",
    "}\n",
    "...\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {JSON body}\n",
    "}\n",
    "```\n",
    "\n",
    "Titan imageの場合の推論入力JSON: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#model-parameters-titan-image-api\n",
    "\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"inputText\": string,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": float,  \n",
    "        \"topP\": float,\n",
    "        \"maxTokenCount\": int,\n",
    "        \"stopSequences\": [string]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Tiatanの場合のバッチ推論入力JSON Lines\n",
    "```JSON\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {\n",
    "        \"inputText\": string,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"temperature\": float,  \n",
    "            \"topP\": float,\n",
    "            \"maxTokenCount\": int,\n",
    "            \"stopSequences\": [string]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "...\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {\n",
    "        \"inputText\": string,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"temperature\": float,  \n",
    "            \"topP\": float,\n",
    "            \"maxTokenCount\": int,\n",
    "            \"stopSequences\": [string]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共通条件設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size:int = 1024\n",
    "cfg_scale:int = 8.0\n",
    "seed:int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height:int = image_size\n",
    "width:int = image_size\n",
    "\n",
    "image_generation_config:dict = {\n",
    "    \"numberOfImages\": 1,\n",
    "    \"quality\": \"standard\",\n",
    "    \"height\": height,\n",
    "    \"width\": width,\n",
    "    \"cfgScale\": cfg_scale,\n",
    "    \"seed\": seed\n",
    "}\n",
    "\n",
    "def return_body_for_titan_image(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt\n",
    "        },\n",
    "        \"imageGenerationConfig\": image_generation_config\n",
    "    }\n",
    "\n",
    "def return_body_for_sd(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"text_prompts\": [{\"text\": prompt}],\n",
    "        \"height\": height,\n",
    "        \"width\": width,\n",
    "        \"cfg_scale\": cfg_scale,\n",
    "        # \"clip_guidance_preset\": string,\n",
    "        # \"sampler\": string,\n",
    "        # \"samples\",\n",
    "        \"seed\": seed,\n",
    "        # \"steps\": int,\n",
    "        # \"style_preset\": string,\n",
    "        # \"extras\": JSON object\n",
    "    }\n",
    "\n",
    "functions = {\n",
    "    \"amazon.titan-image-generator-v1\": return_body_for_titan_image,\n",
    "    \"stability.stable-diffusion-xl-v1\": return_body_for_sd,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単発推論\n",
    "まずは単発を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt:str = \"A dog running at a park.\"\n",
    "\n",
    "from func import generate_image_by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titan image\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"taskType\": \"TEXT_IMAGE\",\n",
    "    \"textToImageParams\": {\n",
    "        \"text\": prompt\n",
    "    },\n",
    "    \"imageGenerationConfig\": image_generation_config\n",
    "}\n",
    "generate_image_by(model_id=\"amazon.titan-image-generator-v1\", body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion-1-0-text-image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"text_prompts\": [{\"text\": prompt}],\n",
    "    \"height\": height,\n",
    "    \"width\": width,\n",
    "    \"cfg_scale\": cfg_scale,\n",
    "    # \"clip_guidance_preset\": string,\n",
    "    # \"sampler\": string,\n",
    "    # \"samples\",\n",
    "    \"seed\": seed,\n",
    "    # \"steps\": int,\n",
    "    # \"style_preset\": string,\n",
    "    # \"extras\" :JSON object\n",
    "}\n",
    "generate_image_by(model_id=\"stability.stable-diffusion-xl-v1\", body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件設定\n",
    "\n",
    "バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "\n",
    "最小も最大も定義されている。そのためリクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "\n",
    "- Titan: 4枚\n",
    "- SD: 10枚\n",
    "\n",
    "程度が最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bedrock\n",
    "_bedrock:bedrock.Bedrock = bedrock.Bedrock(region=\"us-east-1\")\n",
    "\n",
    "from batch import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_images:int = 10\n",
    "\n",
    "batch = Batch(\n",
    "    model_id = \"amazon.titan-image-generator-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = _bedrock.client,\n",
    ")\n",
    "input_key, output_dir = batch.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_images))\n",
    ")\n",
    "! aws s3 cp $input_key -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、\n",
    "\n",
    "- S3に入力ファイルがアップロードされたか\n",
    "- アップロードされたファイルの中身が正しいか\n",
    "\n",
    "を確認するため、S3内のファイルの中身を覗く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.create_job(input_key, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bedrock.group_jobs_by_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ID: {batch.id}\")\n",
    "print(f\"Name: {batch.name}\")\n",
    "\n",
    "import utils\n",
    "utils.wait_until_complete(\n",
    "    get_status = batch.get_status,\n",
    "    stopped_status = ('Completed', 'Failed', 'Stopped'),\n",
    ")\n",
    "\n",
    "print(f\"Error: {batch.error}\")\n",
    "print(f\"Total time: {batch.progress_time}\")\n",
    "\n",
    "! aws s3 cp $output_dir$batch.id/manifest.json.out -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_images:int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"recordId\": \"000000000000\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"2 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000001\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"3 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000002\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"4 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000003\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"5 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000004\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"6 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000005\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"7 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000006\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"8 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000007\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"9 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000008\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"10 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000009\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"11 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n"
     ]
    }
   ],
   "source": [
    "titan = Batch(\n",
    "    model_id = \"amazon.titan-image-generator-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = _bedrock.client,\n",
    ")\n",
    "titan_input_key, titan_output_dir = titan.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_images))\n",
    ")\n",
    "! aws s3 cp $titan_input_key -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"recordId\": \"000000000000\", \"modelInput\": {\"text_prompts\": [{\"text\": \"2 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000001\", \"modelInput\": {\"text_prompts\": [{\"text\": \"3 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000002\", \"modelInput\": {\"text_prompts\": [{\"text\": \"4 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000003\", \"modelInput\": {\"text_prompts\": [{\"text\": \"5 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000004\", \"modelInput\": {\"text_prompts\": [{\"text\": \"6 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000005\", \"modelInput\": {\"text_prompts\": [{\"text\": \"7 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000006\", \"modelInput\": {\"text_prompts\": [{\"text\": \"8 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000007\", \"modelInput\": {\"text_prompts\": [{\"text\": \"9 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000008\", \"modelInput\": {\"text_prompts\": [{\"text\": \"10 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000009\", \"modelInput\": {\"text_prompts\": [{\"text\": \"11 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n"
     ]
    }
   ],
   "source": [
    "sd = Batch(\n",
    "    model_id = \"stability.stable-diffusion-xl-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = _bedrock.client,\n",
    ")\n",
    "sd_input_key, sd_output_dir = sd.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_images))\n",
    ")\n",
    "! aws s3 cp $sd_input_key -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '77a4394e-865a-4fe9-ac1f-d0d543c8e4a4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 09 Feb 2024 07:26:08 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '85',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '77a4394e-865a-4fe9-ac1f-d0d543c8e4a4'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/s4i4js4g82i6'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titan.create_job(titan_input_key, titan_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '761c1e83-f011-46f9-8439-a7d88410671d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 09 Feb 2024 07:26:09 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '85',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '761c1e83-f011-46f9-8439-a7d88410671d'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/wvtqyu73z3yk'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.create_job(sd_input_key, sd_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Completed     66\n",
       "Failed        28\n",
       "InProgress     2\n",
       "Submitted      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bedrock.group_jobs_by_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大キュー数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "Completed     67\n",
      "Failed        29\n",
      "InProgress     2\n",
      "Submitted      2\n",
      "dtype: int64\n",
      "status\n",
      "Completed     66\n",
      "Failed        28\n",
      "InProgress     2\n",
      "Submitted      4\n",
      "dtype: int64\n",
      "status\n",
      "Completed     64\n",
      "Failed        28\n",
      "InProgress     2\n",
      "Submitted      6\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ServiceQuotaExceededException",
     "evalue": "An error occurred (ServiceQuotaExceededException) when calling the CreateModelInvocationJob operation: You have reached the quota for number of concurrent invoke-model jobs in progress.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceQuotaExceededException\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb Cell 39\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtime\u001b[39;00m \u001b[39mimport\u001b[39;00m sleep\n\u001b[1;32m      <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     titan\u001b[39m.\u001b[39;49mcreate_job(titan_input_key, titan_output_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     sd\u001b[39m.\u001b[39mcreate_job(sd_input_key, sd_output_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(_bedrock\u001b[39m.\u001b[39mgroup_jobs_by_status())\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/batch.py:40\u001b[0m, in \u001b[0;36mBatch.create_job\u001b[0;34m(self, input_key, output_dir)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_job\u001b[39m(\u001b[39mself\u001b[39m, input_key:\u001b[39mstr\u001b[39m, output_dir:\u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     response:\u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__create_by(input_key, output_dir)\n\u001b[1;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marn \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mjobArn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marn\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/batch.py:71\u001b[0m, in \u001b[0;36mBatch.__create_by\u001b[0;34m(self, input_key, output_dir)\u001b[0m\n\u001b[1;32m     61\u001b[0m place_of_input \u001b[39m=\u001b[39m ({\n\u001b[1;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39ms3InputDataConfig\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m     63\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39ms3Uri\u001b[39m\u001b[39m\"\u001b[39m: input_key\n\u001b[1;32m     64\u001b[0m     }\n\u001b[1;32m     65\u001b[0m })\n\u001b[1;32m     66\u001b[0m place_of_output \u001b[39m=\u001b[39m ({\n\u001b[1;32m     67\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39ms3OutputDataConfig\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m     68\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39ms3Uri\u001b[39m\u001b[39m\"\u001b[39m: output_dir\n\u001b[1;32m     69\u001b[0m     }\n\u001b[1;32m     70\u001b[0m })\n\u001b[0;32m---> 71\u001b[0m response:\u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__bedrock\u001b[39m.\u001b[39;49mcreate_model_invocation_job(\n\u001b[1;32m     72\u001b[0m     roleArn \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__config\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     73\u001b[0m     modelId \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_id,\n\u001b[1;32m     74\u001b[0m     jobName \u001b[39m=\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__condition\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mutils\u001b[39m.\u001b[39;49mget_formatted_time()\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mreplace(\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     75\u001b[0m     inputDataConfig \u001b[39m=\u001b[39;49m place_of_input,\n\u001b[1;32m     76\u001b[0m     outputDataConfig \u001b[39m=\u001b[39;49m place_of_output\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:983\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    979\u001b[0m     error_code \u001b[39m=\u001b[39m error_info\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mQueryErrorCode\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m error_info\u001b[39m.\u001b[39mget(\n\u001b[1;32m    980\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    982\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 983\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    984\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mServiceQuotaExceededException\u001b[0m: An error occurred (ServiceQuotaExceededException) when calling the CreateModelInvocationJob operation: You have reached the quota for number of concurrent invoke-model jobs in progress."
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "while True:\n",
    "    titan.create_job(titan_input_key, titan_output_dir)\n",
    "    sd.create_job(sd_input_key, sd_output_dir)\n",
    "    print(_bedrock.group_jobs_by_status())\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ジョブの状態はこちら: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-list.html\n",
    "\n",
    "ジョブは並列実行されない。\n",
    "\n",
    "複数のジョブを投げることは可能だが、ジョブが順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "\n",
    "よってジョブの並列実行による高速化はされない。\n",
    "\n",
    "またバッチ推論にすることでオンラインより高速化もされない。\n",
    "\n",
    "バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像表示\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにbase64で全画像が入力情報とセットで埋まっている\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "output_dir:str = f\"{dir}/{job_id}\"\n",
    "\n",
    "def get_content_binary(key:str):\n",
    "    output_obj = bucket.Object(key=output_key).get()\n",
    "    binary_contents = output_obj.get(\"Body\").read()\n",
    "    return binary_contents\n",
    "\n",
    "\n",
    "def display_image(image_bytes):\n",
    "    image = Image.open(BytesIO(image_bytes))\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if \"titan\" in model_id:\n",
    "    output_key = f\"{output_dir}/{model_id}.jsonl.out\"\n",
    "    binary_contents = get_content_binary(output_key)\n",
    "\n",
    "    for line in BytesIO(binary_contents):\n",
    "        content = json.loads(line.decode(\"utf-8\"))\n",
    "        # finish_reason = content.get(\"error\")\n",
    "        # if finish_reason is not None: print(f\"Image generation error. Error is {finish_reason}\")\n",
    "        print(content.get(\"modelInput\").get(\"textToImageParams\").get(\"text\"))\n",
    "        base64_image = content.get(\"modelOutput\").get(\"images\")[0]\n",
    "        base64_bytes = base64_image.encode('ascii')\n",
    "        image_bytes = base64.b64decode(base64_bytes)\n",
    "        display_image(image_bytes)\n",
    "elif \"stable\" in model_id:\n",
    "    for record_id in range(number_of_images):\n",
    "        output_key = f\"{output_dir}/{model_id}.{str(record_id).zfill(12)}.1.png\"\n",
    "        binary_contents = get_content_binary(output_key)\n",
    "        print(output_key)\n",
    "        display_image(binary_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs = bedrock.list_model_invocation_jobs().get(\"invocationJobSummaries\")\n",
    "# from pprint import pprint\n",
    "# # pprint(jobs)\n",
    "# for job in jobs:\n",
    "#     # a = f\"{job.get(\"jobArn\")}\"\n",
    "#     print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "### 入出力データ\n",
    "- インターフェイスはS3のみ。\n",
    "- バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- 最小も最大も定義されている。\n",
    "\n",
    "#### 入力データフォーマット\n",
    "- 一枚一枚に対してはオンデマンド推論と同じ。それをJSONLにしてS3に置く。\n",
    "- リクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "    - Titan: 4枚\n",
    "    - SD: 10枚\n",
    "\n",
    "#### 出力データフォーマット\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにバイナリで全画像が入力情報とセットで埋まっている。大量画像入っているのでデカJSONL\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない\n",
    "\n",
    "### ジョブ\n",
    "- ジョブは並列実行されない。\n",
    "- 複数のジョブを投げることは可能だが、順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "- よってジョブの並列実行による高速化はされない。\n",
    "- またバッチ推論にすることでオンラインより高速化もされない。\n",
    "- バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。\n",
    "\n",
    "### 結果\n",
    "600枚全て成功\n",
    "\n",
    "- Titan: 12 sec / image\n",
    "- SD: 7 sec /image　← 70分くらい\n",
    "\n",
    "条件全て揃えられているわけではないので注意"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
