{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 背景\n",
    "- Bedrockのbatch推論のquotaがon demandと関係ない（だからquotaに引っ掛からなくてうれしい）と言う説\n",
    "- text to image (SDXL or Titan or Both)で500枚くらいバッチ推論ジョブを発行してどんな風に実行が完了するか（もしくは完了しないか）を見てみる\n",
    "- On demandのquotaより明らかに早かったら嬉しい\n",
    "\n",
    "\n",
    "## 検証条件\n",
    "- 推論方式: バッチ\n",
    "- 生成: テキスト → 画像\n",
    "- モデル:\n",
    "    - amazon.titan-image-generator-v1\n",
    "    - stability.stable-diffusion-xl-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "### 入出力データ\n",
    "- インターフェイスはS3のみ。\n",
    "- バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- 最小も最大も定義されている。\n",
    "\n",
    "#### 入力データフォーマット\n",
    "- 一枚一枚に対してはオンデマンド推論と同じ。それをJSONLにしてS3に置く。\n",
    "- リクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "    - Titan: 4枚\n",
    "    - SD: 10枚\n",
    "\n",
    "#### 出力データフォーマット\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにバイナリで全画像が入力情報とセットで埋まっている。大量画像入っているのでデカJSONL\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない\n",
    "\n",
    "### ジョブ\n",
    "- ジョブは並列実行されない。\n",
    "- 複数のジョブを投げることは可能だが、順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "- よってジョブの並列実行による高速化はされない。\n",
    "- またバッチ推論にすることでオンラインより高速化もされない。\n",
    "- バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。\n",
    "\n",
    "### 結果\n",
    "600枚全て成功\n",
    "\n",
    "- Titan: 12 sec / image\n",
    "- SD: 7 sec /image　← 70分くらい\n",
    "\n",
    "条件全て揃えられているわけではないので注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公開情報\n",
    "- 開発者ドキュメント: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html\n",
    "- Quota: https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- コードサンプル: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-example.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境準備\n",
    "\n",
    "### 2024.2.1\n",
    "- Public Preview\n",
    "- 利用方法\n",
    "    - REST API: あると思うが面倒\n",
    "    - CLI: 無さそう\n",
    "    - SDK: プレビューのがある\n",
    "        - PythonとJavaのみ\n",
    "        - ただし他サービスと同様、プレビュー状態のAPIは一般公開SDKに含まれていない\n",
    "        - そのため以下の公式whlからインストールが必要\n",
    "        - https://d2eo22ngex1n9g.cloudfront.net/Documentation/SDK/bedrock-python-sdk-reinvent.zip\n",
    "    - コンソール: 無さそう\n",
    "\n",
    "Python SDKを使うこととし、以下でSDKのインストールをする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! chmod +x install_sdk.sh\n",
    "! ./install_sdk.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記実行後、カーネルの再起動が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import Application\n",
    "Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```aws s3 cp``` などをするため、AWS CLIがあるか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! aws --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データフォーマット\n",
    "\n",
    "参考: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html\n",
    "\n",
    "以下、サンプルの入力JSON\n",
    "\n",
    "入力JSON Linesフォーマット\n",
    "```JSON\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {JSON body}\n",
    "}\n",
    "...\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {JSON body}\n",
    "}\n",
    "```\n",
    "\n",
    "Titan imageの場合の推論入力JSON: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#model-parameters-titan-image-api\n",
    "\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"inputText\": string,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": float,  \n",
    "        \"topP\": float,\n",
    "        \"maxTokenCount\": int,\n",
    "        \"stopSequences\": [string]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Tiatanの場合のバッチ推論入力JSON Lines\n",
    "```JSON\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {\n",
    "        \"inputText\": string,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"temperature\": float,  \n",
    "            \"topP\": float,\n",
    "            \"maxTokenCount\": int,\n",
    "            \"stopSequences\": [string]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "...\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {\n",
    "        \"inputText\": string,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"temperature\": float,  \n",
    "            \"topP\": float,\n",
    "            \"maxTokenCount\": int,\n",
    "            \"stopSequences\": [string]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共通条件設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size:int = 1024\n",
    "cfg_scale:int = 8.0\n",
    "seed:int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height:int = image_size\n",
    "width:int = image_size\n",
    "\n",
    "image_generation_config:dict = {\n",
    "    \"numberOfImages\": 1,\n",
    "    \"quality\": \"standard\",\n",
    "    \"height\": height,\n",
    "    \"width\": width,\n",
    "    \"cfgScale\": cfg_scale,\n",
    "    \"seed\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_body_for_claude(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"prompt\": f\"\\n\\nHuman:{prompt}\\n\\nAssistant:\",\n",
    "        \"max_tokens_to_sample\": 4096,\n",
    "        # \"temperature\": float,\n",
    "        # \"top_p\": float,\n",
    "        # \"top_k\": int,\n",
    "        # \"stop_sequences\": [string]\n",
    "    }\n",
    "\n",
    "def return_body_for_titan_image(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt\n",
    "        },\n",
    "        \"imageGenerationConfig\": image_generation_config\n",
    "    }\n",
    "\n",
    "def return_body_for_sd(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"text_prompts\": [{\"text\": prompt}],\n",
    "        \"height\": height,\n",
    "        \"width\": width,\n",
    "        \"cfg_scale\": cfg_scale,\n",
    "        # \"clip_guidance_preset\": string,\n",
    "        # \"sampler\": string,\n",
    "        # \"samples\",\n",
    "        \"seed\": seed,\n",
    "        # \"steps\": int,\n",
    "        # \"style_preset\": string,\n",
    "        # \"extras\": JSON object\n",
    "    }\n",
    "\n",
    "functions = {\n",
    "    'anthropic.claude-v2:1': return_body_for_claude,\n",
    "    'amazon.titan-image-generator-v1': return_body_for_titan_image,\n",
    "    'stability.stable-diffusion-xl-v1': return_body_for_sd,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件設定\n",
    "\n",
    "バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "\n",
    "最小も最大も定義されている。そのためリクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "\n",
    "- Titan: 4枚\n",
    "- SD: 10枚\n",
    "\n",
    "程度が最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock import Bedrock\n",
    "bedrock:Bedrock = Bedrock(region=\"us-east-1\")\n",
    "\n",
    "from batch import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_prompts:int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = Batch(\n",
    "    model_id = \"amazon.titan-image-generator-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = bedrock,\n",
    ")\n",
    "ti_job_name, ti_output_dir = ti.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_prompts))\n",
    ")\n",
    "! aws s3 cp s3://$Batch.bucket_name/$ti_output_dir$Batch.jsonl_file_name -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = Batch(\n",
    "    model_id = \"stability.stable-diffusion-xl-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = bedrock,\n",
    ")\n",
    "sd_job_name, sd_output_dir = sd.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_prompts))\n",
    ")\n",
    "! aws s3 cp s3://$Batch.bucket_name/$sd_output_dir$Batch.jsonl_file_name -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti.create_job(ti_job_name, ti_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.create_job(sd_job_name, sd_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all jobs: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "status\n",
       "Completed    70\n",
       "Failed       28\n",
       "Stopped       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.group_jobs_by_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大キュー数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "while True:\n",
    "    ti.create_job(ti_job_name, ti_output_dir)\n",
    "    sd.create_job(sd_job_name, sd_output_dir)\n",
    "    print(_bedrock.group_jobs_by_status())\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"recordId\": \"000000000000\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:0 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000001\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:1 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000002\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:2 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000003\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:3 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000004\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:4 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000005\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:5 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000006\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:6 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000007\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:7 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000008\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:8 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n",
      "{\"recordId\": \"000000000009\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:9 + 1 = ?\\n\\nAssistant:\", \"max_tokens_to_sample\": 4096}}\n"
     ]
    }
   ],
   "source": [
    "claude = Batch(\n",
    "    model_id = 'anthropic.claude-v2:1',\n",
    "    functions = functions,\n",
    "    bedrock = bedrock,\n",
    ")\n",
    "claude_job_name, claude_output_dir = claude.create_inputs_by(\n",
    "    prompts = (f\"{i} + 1 = ?\" for i in range(number_of_prompts))\n",
    ")\n",
    "! aws s3 cp s3://$Batch.bucket_name/$claude_output_dir$Batch.jsonl_file_name -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f4871676-80a0-4c9f-b8aa-9c0e80c8ab35',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 10 Feb 2024 23:36:48 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '85',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'f4871676-80a0-4c9f-b8aa-9c0e80c8ab35'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/to9en9groort'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude.create_job(claude_job_name, claude_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all jobs: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "status\n",
       "Completed    69\n",
       "Failed       28\n",
       "Stopped       2\n",
       "Submitted     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.group_jobs_by_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobName</th>\n",
       "      <th>modelId</th>\n",
       "      <th>roleArn</th>\n",
       "      <th>status</th>\n",
       "      <th>submitTime</th>\n",
       "      <th>lastModifiedTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobArn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/to9en9groort</th>\n",
       "      <td>anthropic.claude-v2-1-10-20240211-083648</td>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>arn:aws:iam::624045005200:role/Admin_role_for_...</td>\n",
       "      <td>Submitted</td>\n",
       "      <td>2024-02-10 23:36:48.327000+00:00</td>\n",
       "      <td>2024-02-10 23:36:48.327000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/6h6tr72zk7w2</th>\n",
       "      <td>amazon.titan-image-generator-v1-10-20240210-07...</td>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>arn:aws:iam::624045005200:role/Admin_role_for_...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2024-02-09 22:57:06.329000+00:00</td>\n",
       "      <td>2024-02-09 23:01:57.664000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/yn01y09bc3o6</th>\n",
       "      <td>amazon.titan-image-generator-v1-10-20240210-07...</td>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>arn:aws:iam::624045005200:role/Admin_role_for_...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2024-02-09 22:47:12.539000+00:00</td>\n",
       "      <td>2024-02-09 22:52:00.839000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              jobName  \\\n",
       "jobArn                                                                                                  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...           anthropic.claude-v2-1-10-20240211-083648   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  amazon.titan-image-generator-v1-10-20240210-07...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  amazon.titan-image-generator-v1-10-20240210-07...   \n",
       "\n",
       "                                                                                              modelId  \\\n",
       "jobArn                                                                                                  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "\n",
       "                                                                                              roleArn  \\\n",
       "jobArn                                                                                                  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:iam::624045005200:role/Admin_role_for_...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:iam::624045005200:role/Admin_role_for_...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:iam::624045005200:role/Admin_role_for_...   \n",
       "\n",
       "                                                       status  \\\n",
       "jobArn                                                          \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  Submitted   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  Completed   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  Completed   \n",
       "\n",
       "                                                                         submitTime  \\\n",
       "jobArn                                                                                \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-10 23:36:48.327000+00:00   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 22:57:06.329000+00:00   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 22:47:12.539000+00:00   \n",
       "\n",
       "                                                                   lastModifiedTime  \n",
       "jobArn                                                                               \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-10 23:36:48.327000+00:00  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 23:01:57.664000+00:00  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 22:52:00.839000+00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.get_dataframe_of_jobs(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claude.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: to9en9groort\n",
      "Name: anthropic.claude-v2-1-10-20240211-083648\n",
      "\n",
      "Submitted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m claude\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m      <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39m aws s3 cp $claude_output_dir$claude.id/manifest.json.out -\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/batch.py:77\u001b[0m, in \u001b[0;36mBatch.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mName: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m---> 77\u001b[0m utils\u001b[39m.\u001b[39;49mwait_until_complete(\n\u001b[1;32m     78\u001b[0m     get_status \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_status,\n\u001b[1;32m     79\u001b[0m     stopped_status \u001b[39m=\u001b[39;49m (\u001b[39m'\u001b[39;49m\u001b[39mCompleted\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mFailed\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mStopped\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     81\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m     82\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/utils.py:23\u001b[0m, in \u001b[0;36mwait_until_complete\u001b[0;34m(get_status, stopped_status)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(status)\n\u001b[1;32m     22\u001b[0m \u001b[39mwhile\u001b[39;00m status \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopped_status:\n\u001b[0;32m---> 23\u001b[0m     status, time_delta \u001b[39m=\u001b[39m __wait(get_status\u001b[39m=\u001b[39;49mget_status, monitored_status\u001b[39m=\u001b[39;49mstatus)\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mtime_delta\u001b[39m}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(status)\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/utils.py:35\u001b[0m, in \u001b[0;36m__wait\u001b[0;34m(get_status, monitored_status)\u001b[0m\n\u001b[1;32m     33\u001b[0m started_time \u001b[39m=\u001b[39m perf_counter()\n\u001b[1;32m     34\u001b[0m \u001b[39mwhile\u001b[39;00m status \u001b[39m==\u001b[39m monitored_status:\n\u001b[0;32m---> 35\u001b[0m     status:\u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m get_status()\n\u001b[1;32m     36\u001b[0m     sleep(\u001b[39m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m ended_time \u001b[39m=\u001b[39m perf_counter()\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/batch.py:51\u001b[0m, in \u001b[0;36mBatch.get_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_status\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m---> 51\u001b[0m     job_info:\u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_job_info()\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m job_info\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/batch.py:56\u001b[0m, in \u001b[0;36mBatch.get_job_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_job_info\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     job_info:\u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__bedrock\u001b[39m.\u001b[39;49mget_job_info(job_arn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49marn)\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname:\u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m job_info\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mjobName\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus:\u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m job_info\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/amazon-sagemaker-examples/bedrock/batch_inference/bedrock.py:73\u001b[0m, in \u001b[0;36mBedrock.get_job_info\u001b[0;34m(self, job_arn)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_job_info\u001b[39m(\u001b[39mself\u001b[39m, job_arn:\u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mget_model_invocation_job(jobIdentifier\u001b[39m=\u001b[39;49mjob_arn)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:963\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    959\u001b[0m     maybe_compress_request(\n\u001b[1;32m    960\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mconfig, request_dict, operation_model\n\u001b[1;32m    961\u001b[0m     )\n\u001b[1;32m    962\u001b[0m     apply_request_checksum(request_dict)\n\u001b[0;32m--> 963\u001b[0m     http, parsed_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    964\u001b[0m         operation_model, request_dict, request_context\n\u001b[1;32m    965\u001b[0m     )\n\u001b[1;32m    967\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m    968\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mafter-call.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{operation_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    969\u001b[0m         service_id\u001b[39m=\u001b[39mservice_id, operation_name\u001b[39m=\u001b[39moperation_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m     context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m    975\u001b[0m )\n\u001b[1;32m    977\u001b[0m \u001b[39mif\u001b[39;00m http\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:989\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m    988\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 989\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_endpoint\u001b[39m.\u001b[39;49mmake_request(operation_model, request_dict)\n\u001b[1;32m    990\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    991\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m    992\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mafter-call-error.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{operation_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    993\u001b[0m                 service_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_model\u001b[39m.\u001b[39mservice_id\u001b[39m.\u001b[39mhyphenize(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m             context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m    998\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/endpoint.py:119\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    114\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaking request for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m with params: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m         operation_model,\n\u001b[1;32m    117\u001b[0m         request_dict,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(request_dict, operation_model)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/endpoint.py:199\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_retries_context(context, attempts)\n\u001b[1;32m    198\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_request(request_dict, operation_model)\n\u001b[0;32m--> 199\u001b[0m success_response, exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_response(\n\u001b[1;32m    200\u001b[0m     request, operation_model, context\n\u001b[1;32m    201\u001b[0m )\n\u001b[1;32m    202\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_retry(\n\u001b[1;32m    203\u001b[0m     attempts,\n\u001b[1;32m    204\u001b[0m     operation_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m     exception,\n\u001b[1;32m    208\u001b[0m ):\n\u001b[1;32m    209\u001b[0m     attempts \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/endpoint.py:241\u001b[0m, in \u001b[0;36mEndpoint._get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_response\u001b[39m(\u001b[39mself\u001b[39m, request, operation_model, context):\n\u001b[1;32m    236\u001b[0m     \u001b[39m# This will return a tuple of (success_response, exception)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[39m# and success_response is itself a tuple of\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# (http_response, parsed_dict).\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[39m# If an exception occurs then the success_response is None.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[39m# If no exception occurs then exception is None.\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     success_response, exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_get_response(\n\u001b[1;32m    242\u001b[0m         request, operation_model, context\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m     kwargs_to_emit \u001b[39m=\u001b[39m {\n\u001b[1;32m    245\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresponse_dict\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mparsed_response\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    247\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m: context,\n\u001b[1;32m    248\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mexception\u001b[39m\u001b[39m'\u001b[39m: exception,\n\u001b[1;32m    249\u001b[0m     }\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m success_response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/endpoint.py:281\u001b[0m, in \u001b[0;36mEndpoint._do_get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    279\u001b[0m     http_response \u001b[39m=\u001b[39m first_non_none_response(responses)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m http_response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m         http_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send(request)\n\u001b[1;32m    282\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPClientError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mNone\u001b[39;00m, e)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/endpoint.py:377\u001b[0m, in \u001b[0;36mEndpoint._send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_send\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[0;32m--> 377\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhttp_session\u001b[39m.\u001b[39;49msend(request)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/httpsession.py:464\u001b[0m, in \u001b[0;36mURLLib3Session.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    461\u001b[0m     conn\u001b[39m.\u001b[39mproxy_headers[\u001b[39m'\u001b[39m\u001b[39mhost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m host\n\u001b[1;32m    463\u001b[0m request_target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_request_target(request\u001b[39m.\u001b[39murl, proxy_url)\n\u001b[0;32m--> 464\u001b[0m urllib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    465\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    466\u001b[0m     url\u001b[39m=\u001b[39;49mrequest_target,\n\u001b[1;32m    467\u001b[0m     body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    468\u001b[0m     headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    469\u001b[0m     retries\u001b[39m=\u001b[39;49mRetry(\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    470\u001b[0m     assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    471\u001b[0m     preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    472\u001b[0m     decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    473\u001b[0m     chunked\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chunked(request\u001b[39m.\u001b[39;49mheaders),\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m http_response \u001b[39m=\u001b[39m botocore\u001b[39m.\u001b[39mawsrequest\u001b[39m.\u001b[39mAWSResponse(\n\u001b[1;32m    477\u001b[0m     request\u001b[39m.\u001b[39murl,\n\u001b[1;32m    478\u001b[0m     urllib_response\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    479\u001b[0m     urllib_response\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    480\u001b[0m     urllib_response,\n\u001b[1;32m    481\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m request\u001b[39m.\u001b[39mstream_output:\n\u001b[1;32m    484\u001b[0m     \u001b[39m# Cause the raw stream to be exhausted immediately. We do it\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39m# this way instead of using preload_content because\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     \u001b[39m# preload_content will never buffer chunked responses\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    716\u001b[0m     conn,\n\u001b[1;32m    717\u001b[0m     method,\n\u001b[1;32m    718\u001b[0m     url,\n\u001b[1;32m    719\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    720\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    721\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    722\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    723\u001b[0m )\n\u001b[1;32m    725\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "claude.wait()\n",
    "! aws s3 cp $claude_output_dir$claude.id/manifest.json.out -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ジョブの状態はこちら: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-list.html\n",
    "\n",
    "ジョブは並列実行されない。\n",
    "\n",
    "複数のジョブを投げることは可能だが、ジョブが順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "\n",
    "よってジョブの並列実行による高速化はされない。\n",
    "\n",
    "またバッチ推論にすることでオンラインより高速化もされない。\n",
    "\n",
    "バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像表示\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにbase64で全画像が入力情報とセットで埋まっている\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "\n",
    "# output_dir:str = f\"{dir}/{job_id}\"\n",
    "\n",
    "# def get_content_binary(key:str):\n",
    "#     output_obj = bucket.Object(key=output_key).get()\n",
    "#     binary_contents = output_obj.get(\"Body\").read()\n",
    "#     return binary_contents\n",
    "\n",
    "\n",
    "# def display_image(image_bytes):\n",
    "#     image = Image.open(BytesIO(image_bytes))\n",
    "#     image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# if \"titan\" in model_id:\n",
    "#     output_key = f\"{output_dir}/{model_id}.jsonl.out\"\n",
    "#     binary_contents = get_content_binary(output_key)\n",
    "\n",
    "#     for line in BytesIO(binary_contents):\n",
    "#         content = json.loads(line.decode(\"utf-8\"))\n",
    "#         # finish_reason = content.get(\"error\")\n",
    "#         # if finish_reason is not None: print(f\"Image generation error. Error is {finish_reason}\")\n",
    "#         print(content.get(\"modelInput\").get(\"textToImageParams\").get(\"text\"))\n",
    "#         base64_image = content.get(\"modelOutput\").get(\"images\")[0]\n",
    "#         base64_bytes = base64_image.encode('ascii')\n",
    "#         image_bytes = base64.b64decode(base64_bytes)\n",
    "#         display_image(image_bytes)\n",
    "# elif \"stable\" in model_id:\n",
    "#     for record_id in range(number_of_prompts):\n",
    "#         output_key = f\"{output_dir}/{model_id}.{str(record_id).zfill(12)}.1.png\"\n",
    "#         binary_contents = get_content_binary(output_key)\n",
    "#         print(output_key)\n",
    "#         display_image(binary_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion': ' 2', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.invoke(\n",
    "    body = return_body_for_claude(prompt='1 + 1 = ?'),\n",
    "    model_id = 'anthropic.claude-v2:1',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "### 入出力データ\n",
    "- インターフェイスはS3のみ。\n",
    "- バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- 最小も最大も定義されている。\n",
    "\n",
    "#### 入力データフォーマット\n",
    "- 一枚一枚に対してはオンデマンド推論と同じ。それをJSONLにしてS3に置く。\n",
    "- リクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "    - Titan: 4枚\n",
    "    - SD: 10枚\n",
    "\n",
    "#### 出力データフォーマット\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにバイナリで全画像が入力情報とセットで埋まっている。大量画像入っているのでデカJSONL\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない\n",
    "\n",
    "### ジョブ\n",
    "- ジョブは並列実行されない。\n",
    "- 複数のジョブを投げることは可能だが、順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "- よってジョブの並列実行による高速化はされない。\n",
    "- またバッチ推論にすることでオンラインより高速化もされない。\n",
    "- バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。\n",
    "\n",
    "### 結果\n",
    "600枚全て成功\n",
    "\n",
    "- Titan: 12 sec / image\n",
    "- SD: 7 sec /image　← 70分くらい\n",
    "\n",
    "条件全て揃えられているわけではないので注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単発推論\n",
    "まずは単発を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titan image\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt:str = \"A dog running at a park.\"\n",
    "\n",
    "from func import generate_image_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"taskType\": \"TEXT_IMAGE\",\n",
    "    \"textToImageParams\": {\n",
    "        \"text\": prompt\n",
    "    },\n",
    "    \"imageGenerationConfig\": image_generation_config\n",
    "}\n",
    "generate_image_by(model_id=\"amazon.titan-image-generator-v1\", body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion-1-0-text-image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"text_prompts\": [{\"text\": prompt}],\n",
    "    \"height\": height,\n",
    "    \"width\": width,\n",
    "    \"cfg_scale\": cfg_scale,\n",
    "    # \"clip_guidance_preset\": string,\n",
    "    # \"sampler\": string,\n",
    "    # \"samples\",\n",
    "    \"seed\": seed,\n",
    "    # \"steps\": int,\n",
    "    # \"style_preset\": string,\n",
    "    # \"extras\" :JSON object\n",
    "}\n",
    "generate_image_by(model_id=\"stability.stable-diffusion-xl-v1\", body=body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
