{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 背景\n",
    "- Bedrockのbatch推論のquotaがon demandと関係ない（だからquotaに引っ掛からなくてうれしい）と言う説\n",
    "- text to image (SDXL or Titan or Both)で500枚くらいバッチ推論ジョブを発行してどんな風に実行が完了するか（もしくは完了しないか）を見てみる\n",
    "- On demandのquotaより明らかに早かったら嬉しい\n",
    "\n",
    "\n",
    "## 検証条件\n",
    "- 推論方式: バッチ\n",
    "- 生成: テキスト → 画像\n",
    "- モデル:\n",
    "    - amazon.titan-image-generator-v1\n",
    "    - stability.stable-diffusion-xl-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "### 入出力データ\n",
    "- インターフェイスはS3のみ。\n",
    "- バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- 最小も最大も定義されている。\n",
    "\n",
    "#### 入力データフォーマット\n",
    "- 一枚一枚に対してはオンデマンド推論と同じ。それをJSONLにしてS3に置く。\n",
    "- リクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "    - Titan: 4枚\n",
    "    - SD: 10枚\n",
    "\n",
    "#### 出力データフォーマット\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにバイナリで全画像が入力情報とセットで埋まっている。大量画像入っているのでデカJSONL\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない\n",
    "\n",
    "### ジョブ\n",
    "- ジョブは並列実行されない。\n",
    "- 複数のジョブを投げることは可能だが、順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "- よってジョブの並列実行による高速化はされない。\n",
    "- またバッチ推論にすることでオンラインより高速化もされない。\n",
    "- バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。\n",
    "\n",
    "### 結果\n",
    "600枚全て成功\n",
    "\n",
    "- Titan: 12 sec / image\n",
    "- SD: 7 sec /image　← 70分くらい\n",
    "\n",
    "条件全て揃えられているわけではないので注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公開情報\n",
    "- 開発者ドキュメント: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html\n",
    "- Quota: https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- コードサンプル: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-example.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境準備\n",
    "\n",
    "### 2024.2.1\n",
    "- Public Preview\n",
    "- 利用方法\n",
    "    - REST API: あると思うが面倒\n",
    "    - CLI: 無さそう\n",
    "    - SDK: プレビューのがある\n",
    "        - PythonとJavaのみ\n",
    "        - ただし他サービスと同様、プレビュー状態のAPIは一般公開SDKに含まれていない\n",
    "        - そのため以下の公式whlからインストールが必要\n",
    "        - https://d2eo22ngex1n9g.cloudfront.net/Documentation/SDK/bedrock-python-sdk-reinvent.zip\n",
    "    - コンソール: 無さそう\n",
    "\n",
    "Python SDKを使うこととし、以下でSDKのインストールをする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! chmod +x install_sdk.sh\n",
    "! ./install_sdk.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記実行後、カーネルの再起動が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import Application\n",
    "Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```aws s3 cp``` などをするため、AWS CLIがあるか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! aws --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データフォーマット\n",
    "\n",
    "参考: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html\n",
    "\n",
    "以下、サンプルの入力JSON\n",
    "\n",
    "入力JSON Linesフォーマット\n",
    "```JSON\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {JSON body}\n",
    "}\n",
    "...\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {JSON body}\n",
    "}\n",
    "```\n",
    "\n",
    "Titan imageの場合の推論入力JSON: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#model-parameters-titan-image-api\n",
    "\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"inputText\": string,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": float,  \n",
    "        \"topP\": float,\n",
    "        \"maxTokenCount\": int,\n",
    "        \"stopSequences\": [string]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Tiatanの場合のバッチ推論入力JSON Lines\n",
    "```JSON\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {\n",
    "        \"inputText\": string,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"temperature\": float,  \n",
    "            \"topP\": float,\n",
    "            \"maxTokenCount\": int,\n",
    "            \"stopSequences\": [string]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "...\n",
    "{\n",
    "    \"recordId\": \"12 character alphanumeric string\",\n",
    "    \"modelInput\": {\n",
    "        \"inputText\": string,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"temperature\": float,  \n",
    "            \"topP\": float,\n",
    "            \"maxTokenCount\": int,\n",
    "            \"stopSequences\": [string]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共通条件設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size:int = 1024\n",
    "cfg_scale:int = 8.0\n",
    "seed:int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height:int = image_size\n",
    "width:int = image_size\n",
    "\n",
    "image_generation_config:dict = {\n",
    "    \"numberOfImages\": 1,\n",
    "    \"quality\": \"standard\",\n",
    "    \"height\": height,\n",
    "    \"width\": width,\n",
    "    \"cfgScale\": cfg_scale,\n",
    "    \"seed\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_body_for_claude(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"prompt\": f\"\\n\\nHuman:{prompt}\\n\\nAssistant:\",\n",
    "        # \"temperature\": float,\n",
    "        # \"top_p\": float,\n",
    "        # \"top_k\": int,\n",
    "        # \"max_tokens_to_sample\": int,\n",
    "        # \"stop_sequences\": [string]\n",
    "    }\n",
    "\n",
    "def return_body_for_titan_image(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt\n",
    "        },\n",
    "        \"imageGenerationConfig\": image_generation_config\n",
    "    }\n",
    "\n",
    "def return_body_for_sd(prompt:str) -> dict:\n",
    "    return {\n",
    "        \"text_prompts\": [{\"text\": prompt}],\n",
    "        \"height\": height,\n",
    "        \"width\": width,\n",
    "        \"cfg_scale\": cfg_scale,\n",
    "        # \"clip_guidance_preset\": string,\n",
    "        # \"sampler\": string,\n",
    "        # \"samples\",\n",
    "        \"seed\": seed,\n",
    "        # \"steps\": int,\n",
    "        # \"style_preset\": string,\n",
    "        # \"extras\": JSON object\n",
    "    }\n",
    "\n",
    "functions = {\n",
    "    'anthropic.claude-v2:1': return_body_for_claude,\n",
    "    'amazon.titan-image-generator-v1': return_body_for_titan_image,\n",
    "    'stability.stable-diffusion-xl-v1': return_body_for_sd,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件設定\n",
    "\n",
    "バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "\n",
    "最小も最大も定義されている。そのためリクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "\n",
    "- Titan: 4枚\n",
    "- SD: 10枚\n",
    "\n",
    "程度が最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bedrock\n",
    "_bedrock:bedrock.Bedrock = bedrock.Bedrock(region=\"us-east-1\")\n",
    "\n",
    "from batch import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"recordId\": \"000000000000\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"2 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000001\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"3 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000002\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"4 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000003\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"5 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000004\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"6 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000005\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"7 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000006\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"8 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000007\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"9 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000008\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"10 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000009\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"11 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n"
     ]
    }
   ],
   "source": [
    "number_of_prompts:int = 10\n",
    "\n",
    "batch = Batch(\n",
    "    model_id = \"amazon.titan-image-generator-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = _bedrock,\n",
    ")\n",
    "input_key, output_dir = batch.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_prompts))\n",
    ")\n",
    "! aws s3 cp $input_key -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '935acd12-a6d5-4611-a17e-45e2b559dcf9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 09 Feb 2024 08:34:15 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '85',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '935acd12-a6d5-4611-a17e-45e2b559dcf9'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/hnkwljadyzsn'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.create_job(input_key, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Completed    69\n",
       "Failed       28\n",
       "Submitted     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bedrock.group_jobs_by_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_prompts:int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"recordId\": \"000000000000\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"2 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000001\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"3 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000002\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"4 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000003\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"5 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000004\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"6 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000005\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"7 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000006\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"8 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000007\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"9 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000008\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"10 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n",
      "{\"recordId\": \"000000000009\", \"modelInput\": {\"taskType\": \"TEXT_IMAGE\", \"textToImageParams\": {\"text\": \"11 dogs running at a park.\"}, \"imageGenerationConfig\": {\"numberOfImages\": 1, \"quality\": \"standard\", \"height\": 1024, \"width\": 1024, \"cfgScale\": 8.0, \"seed\": 0}}}\n"
     ]
    }
   ],
   "source": [
    "ti = Batch(\n",
    "    model_id = \"amazon.titan-image-generator-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = _bedrock,\n",
    ")\n",
    "ti_input_key, ti_output_dir = ti.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_prompts))\n",
    ")\n",
    "! aws s3 cp $ti_input_key -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"recordId\": \"000000000000\", \"modelInput\": {\"text_prompts\": [{\"text\": \"2 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000001\", \"modelInput\": {\"text_prompts\": [{\"text\": \"3 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000002\", \"modelInput\": {\"text_prompts\": [{\"text\": \"4 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000003\", \"modelInput\": {\"text_prompts\": [{\"text\": \"5 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000004\", \"modelInput\": {\"text_prompts\": [{\"text\": \"6 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000005\", \"modelInput\": {\"text_prompts\": [{\"text\": \"7 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000006\", \"modelInput\": {\"text_prompts\": [{\"text\": \"8 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000007\", \"modelInput\": {\"text_prompts\": [{\"text\": \"9 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000008\", \"modelInput\": {\"text_prompts\": [{\"text\": \"10 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n",
      "{\"recordId\": \"000000000009\", \"modelInput\": {\"text_prompts\": [{\"text\": \"11 dogs running at a park.\"}], \"height\": 1024, \"width\": 1024, \"cfg_scale\": 8.0, \"seed\": 0}}\n"
     ]
    }
   ],
   "source": [
    "sd = Batch(\n",
    "    model_id = \"stability.stable-diffusion-xl-v1\",\n",
    "    functions = functions,\n",
    "    bedrock = _bedrock,\n",
    ")\n",
    "sd_input_key, sd_output_dir = sd.create_inputs_by(\n",
    "    prompts = (f\"{i+2} dogs running at a park.\" for i in range(number_of_prompts))\n",
    ")\n",
    "! aws s3 cp $sd_input_key -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti.create_job(ti_input_key, ti_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.create_job(sd_input_key, sd_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bedrock.group_jobs_by_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大キュー数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "while True:\n",
    "    ti.create_job(ti_input_key, ti_output_dir)\n",
    "    sd.create_job(sd_input_key, sd_output_dir)\n",
    "    print(_bedrock.group_jobs_by_status())\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"recordId\": \"000000000000\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:0 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000001\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:1 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000002\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:2 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000003\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:3 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000004\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:4 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000005\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:5 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000006\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:6 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000007\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:7 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000008\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:8 + 1 = ?\\n\\nAssistant:\"}}\n",
      "{\"recordId\": \"000000000009\", \"modelInput\": {\"prompt\": \"\\n\\nHuman:9 + 1 = ?\\n\\nAssistant:\"}}\n"
     ]
    }
   ],
   "source": [
    "claude = Batch(\n",
    "    model_id = 'anthropic.claude-v2:1',\n",
    "    functions = functions,\n",
    "    bedrock = _bedrock.client,\n",
    ")\n",
    "claude_input_key, claude_output_dir = claude.create_inputs_by(\n",
    "    prompts = (f\"{i} + 1 = ?\" for i in range(number_of_prompts))\n",
    ")\n",
    "! aws s3 cp $claude_input_key -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '92e529d2-d765-4299-8513-df30a2530ba5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 09 Feb 2024 08:14:50 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '85',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '92e529d2-d765-4299-8513-df30a2530ba5'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/b91z3s38a1zj'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude.create_job(claude_input_key, claude_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Completed     69\n",
       "Failed        28\n",
       "InProgress     1\n",
       "Stopped        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bedrock.group_jobs_by_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobName</th>\n",
       "      <th>modelId</th>\n",
       "      <th>roleArn</th>\n",
       "      <th>status</th>\n",
       "      <th>submitTime</th>\n",
       "      <th>lastModifiedTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobArn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/hnkwljadyzsn</th>\n",
       "      <td>amazon.titan-image-generator-v1-10-20240209-17...</td>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>arn:aws:iam::624045005200:role/Admin_role_for_...</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>2024-02-09 08:34:15.152000+00:00</td>\n",
       "      <td>2024-02-09 08:34:55.311000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/b91z3s38a1zj</th>\n",
       "      <td>anthropic.claude-v2-1-10-20240209-171450</td>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>arn:aws:iam::624045005200:role/Admin_role_for_...</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>2024-02-09 08:14:50.629000+00:00</td>\n",
       "      <td>2024-02-09 08:37:52.516000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arn:aws:bedrock:us-east-1:624045005200:model-invocation-job/uveo7osa8mzf</th>\n",
       "      <td>anthropic.claude-v2-1-10-20240209-165126</td>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>arn:aws:iam::624045005200:role/Admin_role_for_...</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>2024-02-09 07:51:26.726000+00:00</td>\n",
       "      <td>2024-02-09 08:36:52.658000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              jobName  \\\n",
       "jobArn                                                                                                  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  amazon.titan-image-generator-v1-10-20240209-17...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...           anthropic.claude-v2-1-10-20240209-171450   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...           anthropic.claude-v2-1-10-20240209-165126   \n",
       "\n",
       "                                                                                              modelId  \\\n",
       "jobArn                                                                                                  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "\n",
       "                                                                                              roleArn  \\\n",
       "jobArn                                                                                                  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:iam::624045005200:role/Admin_role_for_...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:iam::624045005200:role/Admin_role_for_...   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  arn:aws:iam::624045005200:role/Admin_role_for_...   \n",
       "\n",
       "                                                        status  \\\n",
       "jobArn                                                           \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...  InProgress   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...     Stopped   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in...     Stopped   \n",
       "\n",
       "                                                                         submitTime  \\\n",
       "jobArn                                                                                \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 08:34:15.152000+00:00   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 08:14:50.629000+00:00   \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 07:51:26.726000+00:00   \n",
       "\n",
       "                                                                   lastModifiedTime  \n",
       "jobArn                                                                               \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 08:34:55.311000+00:00  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 08:37:52.516000+00:00  \n",
       "arn:aws:bedrock:us-east-1:624045005200:model-in... 2024-02-09 08:36:52.658000+00:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bedrock.get_dataframe_of_jobs(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'stop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wlb6pe4mdttlxgh.studio.us-east-1.sagemaker.aws/home/sagemaker-user/amazon-sagemaker-examples/bedrock/batch_inference/batch_inference.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m claude\u001b[39m.\u001b[39;49mstop()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'stop'"
     ]
    }
   ],
   "source": [
    "claude.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: uveo7osa8mzf\n",
      "Name: anthropic.claude-v2-1-10-20240209-165126\n",
      "Submitted\n"
     ]
    }
   ],
   "source": [
    "claude.wait()\n",
    "! aws s3 cp $claude_output_dir$claude.id/manifest.json.out -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ジョブの状態はこちら: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-list.html\n",
    "\n",
    "ジョブは並列実行されない。\n",
    "\n",
    "複数のジョブを投げることは可能だが、ジョブが順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "\n",
    "よってジョブの並列実行による高速化はされない。\n",
    "\n",
    "またバッチ推論にすることでオンラインより高速化もされない。\n",
    "\n",
    "バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像表示\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにbase64で全画像が入力情報とセットで埋まっている\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "\n",
    "# output_dir:str = f\"{dir}/{job_id}\"\n",
    "\n",
    "# def get_content_binary(key:str):\n",
    "#     output_obj = bucket.Object(key=output_key).get()\n",
    "#     binary_contents = output_obj.get(\"Body\").read()\n",
    "#     return binary_contents\n",
    "\n",
    "\n",
    "# def display_image(image_bytes):\n",
    "#     image = Image.open(BytesIO(image_bytes))\n",
    "#     image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# if \"titan\" in model_id:\n",
    "#     output_key = f\"{output_dir}/{model_id}.jsonl.out\"\n",
    "#     binary_contents = get_content_binary(output_key)\n",
    "\n",
    "#     for line in BytesIO(binary_contents):\n",
    "#         content = json.loads(line.decode(\"utf-8\"))\n",
    "#         # finish_reason = content.get(\"error\")\n",
    "#         # if finish_reason is not None: print(f\"Image generation error. Error is {finish_reason}\")\n",
    "#         print(content.get(\"modelInput\").get(\"textToImageParams\").get(\"text\"))\n",
    "#         base64_image = content.get(\"modelOutput\").get(\"images\")[0]\n",
    "#         base64_bytes = base64_image.encode('ascii')\n",
    "#         image_bytes = base64.b64decode(base64_bytes)\n",
    "#         display_image(image_bytes)\n",
    "# elif \"stable\" in model_id:\n",
    "#     for record_id in range(number_of_prompts):\n",
    "#         output_key = f\"{output_dir}/{model_id}.{str(record_id).zfill(12)}.1.png\"\n",
    "#         binary_contents = get_content_binary(output_key)\n",
    "#         print(output_key)\n",
    "#         display_image(binary_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "### 入出力データ\n",
    "- インターフェイスはS3のみ。\n",
    "- バッチ推論は入出力ファイルサイズ制限がある。モデル間での差分はない。\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html#quotas-batch\n",
    "- 最小も最大も定義されている。\n",
    "\n",
    "#### 入力データフォーマット\n",
    "- 一枚一枚に対してはオンデマンド推論と同じ。それをJSONLにしてS3に置く。\n",
    "- リクエスト枚数が少ないと、ジョブ実行時の序盤にエラーで跳ね返される。\n",
    "    - Titan: 4枚\n",
    "    - SD: 10枚\n",
    "\n",
    "#### 出力データフォーマット\n",
    "それぞれのモデルで出力方法が全く異なるので注意\n",
    "\n",
    "- Titan：単一のJSONLにバイナリで全画像が入力情報とセットで埋まっている。大量画像入っているのでデカJSONL\n",
    "- SD：ファイル名に連番が入った一枚一枚のPNG\n",
    "\n",
    "入力と出力の突き合わせ\n",
    "\n",
    "- Titan：1行ずつの入力と出力がすぐ対応できるので、突き合わせしやすい\n",
    "- SD：連番で突き合わせ作業するしかない\n",
    "\n",
    "### ジョブ\n",
    "- ジョブは並列実行されない。\n",
    "- 複数のジョブを投げることは可能だが、順序保証されて（Undocumented）キューイングされて順次処理される。したがって前のジョブが完了するまで次のジョブは実行されない。\n",
    "- よってジョブの並列実行による高速化はされない。\n",
    "- またバッチ推論にすることでオンラインより高速化もされない。\n",
    "- バッチ推論ジョブの速度はオンデマンド推論を同期処理しているような速度のため、非同期でオンデマンド処理させた方が高速化は可能。\n",
    "\n",
    "### 結果\n",
    "600枚全て成功\n",
    "\n",
    "- Titan: 12 sec / image\n",
    "- SD: 7 sec /image　← 70分くらい\n",
    "\n",
    "条件全て揃えられているわけではないので注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単発推論\n",
    "まずは単発を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titan image\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt:str = \"A dog running at a park.\"\n",
    "\n",
    "from func import generate_image_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"taskType\": \"TEXT_IMAGE\",\n",
    "    \"textToImageParams\": {\n",
    "        \"text\": prompt\n",
    "    },\n",
    "    \"imageGenerationConfig\": image_generation_config\n",
    "}\n",
    "generate_image_by(model_id=\"amazon.titan-image-generator-v1\", body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion\n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion-1-0-text-image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"text_prompts\": [{\"text\": prompt}],\n",
    "    \"height\": height,\n",
    "    \"width\": width,\n",
    "    \"cfg_scale\": cfg_scale,\n",
    "    # \"clip_guidance_preset\": string,\n",
    "    # \"sampler\": string,\n",
    "    # \"samples\",\n",
    "    \"seed\": seed,\n",
    "    # \"steps\": int,\n",
    "    # \"style_preset\": string,\n",
    "    # \"extras\" :JSON object\n",
    "}\n",
    "generate_image_by(model_id=\"stability.stable-diffusion-xl-v1\", body=body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
